import telebot
from dotenv import load_dotenv
import os
import requests
from telebot import types

load_dotenv()

BOT_TOKEN = os.getenv("BOT_TOKEN")
OLLAMA_API = os.getenv("OLLAMA_API", "http://localhost:11434")
DEFAULT_MODEL = os.getenv("DEFAULT_MODEL", "mistral")

bot = telebot.TeleBot(BOT_TOKEN)
user_model = {}

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ –∫ Ollama
def ask_ollama(prompt, model=DEFAULT_MODEL):
    # –ü—Ä–æ—Å—Ç–æ–π –∏ —É–≤–∞–∂–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    formatted_prompt = f"""
    –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å —É–≤–∞–∂–µ–Ω–∏–µ–º –∏ –∫—Ä–∞—Ç–∫–æ, –∫–∞–∫ —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫.
    –í–æ–ø—Ä–æ—Å: {prompt}
    """

    try:
        response = requests.post(
            f"{OLLAMA_API}/api/generate",
            json={
                "model": model,
                "prompt": formatted_prompt,
                "stream": False
            }
        )
        return response.json().get("response", "‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
    except Exception as e:
        return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama:\n{e}"

# –ö–æ–º–∞–Ω–¥–∞ /start
@bot.message_handler(commands=['start'])
def send_welcome(message):
    bot.send_message(message.chat.id,
                     "–ü—Ä–∏–≤–µ—Ç! –Ø –ª–æ–∫–∞–ª—å–Ω—ã–π AI-–±–æ—Ç –Ω–∞ –±–∞–∑–µ Ollama üòé\n"
                     "–û—Ç–ø—Ä–∞–≤—å –º–Ω–µ —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî –∏ —è –æ—Ç–≤–µ—á—É.\n"
                     "–ò—Å–ø–æ–ª—å–∑—É–π /model —á—Ç–æ–±—ã –≤—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å.")

# –ö–æ–º–∞–Ω–¥–∞ /help
@bot.message_handler(commands=['help'])
def send_help(message):
    bot.send_message(message.chat.id,
                     "‚ÑπÔ∏è –ü–æ–º–æ—â—å:\n"
                     "- –ù–∞–ø–∏—à–∏ –ª—é–±–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî —è –æ—Ç–≤–µ—á—É\n"
                     "- /model ‚Äî –≤—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å\n"
                     "- –í—Å–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ —á–µ—Ä–µ–∑ Ollama")

# –ö–æ–º–∞–Ω–¥–∞ /model –¥–ª—è –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏
@bot.message_handler(commands=['model'])
def choose_model(message):
    markup = types.InlineKeyboardMarkup()
    for model in ["mistral", "llama2", "codellama", "gemma", "phi"]:
        markup.add(types.InlineKeyboardButton(model, callback_data=f"model_{model}"))
    bot.send_message(message.chat.id, "–í—ã–±–µ—Ä–∏ –º–æ–¥–µ–ª—å:", reply_markup=markup)

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏
@bot.callback_query_handler(func=lambda call: call.data.startswith("model_"))
def callback_model(call):
    model = call.data.split("_")[1]
    user_model[call.from_user.id] = model
    bot.answer_callback_query(call.id, f"–ú–æ–¥–µ–ª—å –≤—ã–±—Ä–∞–Ω–∞: {model}")
    bot.send_message(call.message.chat.id, f"‚úÖ –¢–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å: *{model}*", parse_mode="Markdown")

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
@bot.message_handler(func=lambda message: not message.text.startswith("/"))
def handle_message(message):
    model = user_model.get(message.from_user.id, DEFAULT_MODEL)
    bot.send_chat_action(message.chat.id, 'typing')
    response = ask_ollama(message.text, model=model)
    bot.reply_to(message, response)

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
print("ü§ñ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω.")
bot.polling()
